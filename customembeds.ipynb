{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "56f50e95b245e7041cda2f292062fbc926f5f5ac"
   },
   "source": [
    "# **How to train your custom word embeddings**\n",
    "\n",
    "In this notebook, you will learn how to train your custom word2vec using Gensim.\n",
    "\n",
    "For those who are new to word embeddings and would like to find out more, you can check out the following articles:\n",
    "1. [Introduction to Word Embedding and Word2Vec](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa)\n",
    "2. [A Beginner's Guide to Word2Vec and Neural Word Embeddings](https://skymind.ai/wiki/word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "21a555afb7da7fcaf6b61371e472d4b8fae1e49d"
   },
   "outputs": [],
   "source": [
    "def split_fslash(x):\n",
    "    x = x.split('/')[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "d1600260b397d730112eb0af66a2c7e10443fadf"
   },
   "outputs": [],
   "source": [
    "def split_underscore(x):\n",
    "    x = x.split('_')[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "41aea812920c93fd76c4b852814298c88f9bcf73"
   },
   "outputs": [],
   "source": [
    "def preprocessing(titles_array,image_path_array):\n",
    "    \n",
    "    #Retrieve the category from image_path (E.g. beauty, fashion, mobile) and append to title column\n",
    "    df_train['splitted'] = (image_path_array.apply(split_fslash)).apply(split_underscore)\n",
    "    df_train[\"processed\"] = titles_array.map(str) + ' ' + df_train['splitted']\n",
    "    \n",
    "    processed_array = []\n",
    "    \n",
    "    for title in tqdm(df_train[\"processed\"]):\n",
    "        \n",
    "        # remove other non-alphabets symbols with space (i.e. keep only alphabets and whitespaces).\n",
    "        processed = re.sub('[^a-zA-Z ]', '', title)\n",
    "        \n",
    "        words = processed.split()\n",
    "        \n",
    "        #Remove word with length <= 1\n",
    "        processed_array.append(' '.join([word for word in words if len(word) > 1]))\n",
    "    \n",
    "    return processed_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "821183ea8057c78e9e3280801e5b80329d248ada"
   },
   "source": [
    "## **Something to take note**\n",
    "Word2vec is a **self-supervised** method (well, sort of unsupervised but not unsupervised, since it provides its own labels. check out this [Quora](https://www.quora.com/Is-Word2vec-a-supervised-unsupervised-learning-algorithm) thread for a more detailed explanation), so we can make full use of the entire dataset (including test data) to obtain a more wholesome word embedding representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "dd627323f593ee323a3ae62954bc06ccceca485d"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "eefec6cadf21909d078915466e3fd672d62f4f0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 666615/666615 [00:02<00:00, 227778.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1261 words replaced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172402/172402 [00:00<00:00, 229775.76it/s]\n",
      "100%|██████████| 839017/839017 [00:03<00:00, 254942.09it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train['processed'] = preprocessing(df_train['title'], df_train['image_path'])\n",
    "df_test['processed'] = preprocessing(df_test['title'], df_test['image_path'])\n",
    "\n",
    "sentences = pd.concat([df_train['processed'], df_test['processed']],axis=0)\n",
    "train_sentences = list(sentences.progress_apply(str.split).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "e1acc9328db3e49a478a605c27ceb4886e69513e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken : 1.71 mins\n"
     ]
    }
   ],
   "source": [
    "# Parameters reference : https://www.quora.com/How-do-I-determine-Word2Vec-parameters\n",
    "# Feel free to customise your own embedding\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model = Word2Vec(sentences=train_sentences, \n",
    "                 sg=1, \n",
    "                 size=300,  \n",
    "                 workers=4)\n",
    "\n",
    "print(f'Time taken : {(time.time() - start_time) / 60:.2f} mins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e6820a6e76f3ed9f8386c4eddcdbeb9fb45e6e6b"
   },
   "source": [
    "## **Pretty fast isn't it.**\n",
    "\n",
    "Let's check out some of the features of the customised word vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "f4cc2a2eb6e1a836b2fb39bdd1f1572ebde0517d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16689"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of vocab in our custom word embedding\n",
    "\n",
    "len(model.wv.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "f288af1fc4d32841e948759840296956167ce78e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the dimension of each word (we set it to 100 in the above training step)\n",
    "\n",
    "model.wv.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "7ddfb22a1b2f0ef3a7b167580cc7abc324643730"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.71527621e-02,  2.20016912e-01, -1.81544483e-01,  1.29227087e-01,\n",
       "       -3.59647930e-01,  1.92518815e-01,  1.16994448e-01, -4.39830840e-01,\n",
       "       -4.36425090e-01,  9.08169299e-02, -9.80512891e-03,  9.03804302e-02,\n",
       "       -1.96560979e-01,  1.55536113e-02,  6.76497877e-01, -2.19069839e-01,\n",
       "        1.93168953e-01,  1.57927707e-01,  8.54952186e-02, -3.60724628e-01,\n",
       "       -4.39989269e-01,  1.73035692e-02, -4.53415483e-01, -4.47129905e-01,\n",
       "        5.90981185e-01, -5.24166882e-01, -2.68053353e-01,  2.26392657e-01,\n",
       "       -1.52156409e-02,  2.70230621e-01, -3.76996547e-02, -2.12974511e-02,\n",
       "       -7.87326694e-01,  1.80330351e-01,  1.19560681e-01,  9.01071951e-02,\n",
       "        1.70087755e-01,  1.80407032e-01,  2.25447584e-02,  8.44595730e-02,\n",
       "        1.05461165e-01, -2.79203117e-01, -1.22048885e-01, -8.06665421e-02,\n",
       "       -3.66776317e-01,  1.57191247e-01, -1.66163549e-01, -7.57468818e-03,\n",
       "       -7.27388859e-02, -3.52258623e-01, -7.49977827e-02,  5.49288869e-01,\n",
       "       -3.87300283e-01,  4.99612331e-01, -1.14031166e-01,  1.89439297e-01,\n",
       "        3.32212865e-01,  6.85561478e-01, -1.55512348e-01,  5.05095795e-02,\n",
       "       -3.55825245e-01,  3.90929103e-01, -6.54425994e-02,  3.90678138e-01,\n",
       "        3.12379032e-01, -4.45077032e-01, -3.17118131e-02,  2.33998120e-01,\n",
       "       -4.96498108e-01,  4.05607164e-01, -2.65733659e-01, -3.98065776e-01,\n",
       "       -1.72346428e-01,  3.80116373e-01,  1.94099382e-01, -7.54367337e-02,\n",
       "       -5.17763458e-02, -3.82661283e-01,  4.29366827e-01, -2.14840725e-01,\n",
       "        3.66879493e-01,  2.99529225e-01,  1.20077370e-04,  3.51083189e-01,\n",
       "        6.06110729e-02,  3.43710452e-01, -7.69478008e-02,  3.25408697e-01,\n",
       "       -1.03162788e-01,  5.83897866e-02,  1.05113968e-01,  4.85376447e-01,\n",
       "       -1.88430585e-02, -4.89897542e-02,  2.57867426e-01,  4.16616112e-01,\n",
       "       -5.65765023e-01,  1.96731865e-01,  6.66654229e-01, -1.89149544e-01,\n",
       "        2.84390509e-01, -1.48529813e-01, -3.54188949e-01, -1.57745853e-01,\n",
       "       -2.15151742e-01, -3.61446679e-01, -6.50291517e-02, -2.92804800e-02,\n",
       "        2.28802443e-01, -1.39878929e-01,  2.03676373e-02,  8.34194720e-02,\n",
       "       -2.23179102e-01,  2.81109244e-01, -1.25707220e-02,  1.45105999e-02,\n",
       "        2.02387124e-01, -7.28295967e-02,  8.25917423e-02,  6.02985859e-01,\n",
       "        1.98811248e-01,  4.24379379e-01,  1.73783407e-01, -5.16117275e-01,\n",
       "        2.14328036e-01,  3.34366381e-01, -1.41441777e-01, -1.36411875e-01,\n",
       "       -3.06508541e-01, -3.81933272e-01,  4.80298735e-02,  1.12159578e-02,\n",
       "        5.94040990e-01, -2.33895361e-01,  2.98058689e-01, -3.58900689e-02,\n",
       "       -7.39817172e-02,  4.69947755e-02,  4.03880924e-02,  1.55570097e-02,\n",
       "       -3.25284377e-02, -4.90238935e-01, -4.59183514e-01,  3.95292908e-01,\n",
       "        3.18696886e-01,  1.42835796e-01, -3.18247825e-01,  4.01562691e-01,\n",
       "        1.55287907e-01,  1.15970470e-01,  1.51719004e-01,  2.20813110e-01,\n",
       "        1.45182893e-01, -5.83503880e-02, -1.11961171e-01, -5.97178154e-02,\n",
       "        4.69834358e-01, -1.53992504e-01, -3.70539278e-01, -1.45190451e-02,\n",
       "       -3.20570208e-02,  1.97333306e-01, -1.40791506e-01,  1.68389991e-01,\n",
       "        1.80308864e-01,  2.05889732e-01, -1.59038529e-01,  2.44142581e-02,\n",
       "       -1.46912545e-01,  1.07461341e-01,  6.42145813e-01,  2.91117370e-01,\n",
       "       -3.24515969e-01,  1.92768514e-01, -4.11127545e-02,  5.80094494e-02,\n",
       "       -3.04012187e-02,  4.62979451e-02, -1.63214147e-01, -2.59939164e-01,\n",
       "        5.53393848e-02,  2.29856700e-01, -1.17665663e-01, -1.65978685e-01,\n",
       "       -1.43168345e-01, -1.96536362e-01,  1.22911446e-01,  1.04422115e-01,\n",
       "       -3.47456545e-01,  3.50167423e-01, -6.17336072e-02, -2.41682783e-01,\n",
       "       -1.09194197e-01,  4.93270397e-01, -1.71787858e-01,  1.27790585e-01,\n",
       "        1.57528311e-01,  2.56708622e-01,  1.25520796e-01, -2.33369932e-01,\n",
       "        2.47339085e-01,  2.59555757e-01,  3.69037658e-01, -1.65720806e-01,\n",
       "       -9.69946086e-02, -2.08030897e-03, -4.22395855e-01, -3.87709200e-01,\n",
       "        8.53004027e-03,  4.12574261e-01, -1.48430601e-01,  1.46313325e-01,\n",
       "        1.97530255e-01, -9.72610414e-02,  3.13451253e-02, -3.24888080e-01,\n",
       "        2.62772501e-01,  5.08819632e-02, -2.61709373e-02, -1.52422786e-01,\n",
       "       -4.84244674e-01, -1.25140294e-01,  1.42151639e-01, -1.52248800e-01,\n",
       "       -1.72318220e-01, -2.68672049e-01,  1.24356106e-01,  1.20879970e-01,\n",
       "       -1.69377461e-01, -1.27992496e-01,  6.37147129e-01, -1.54667228e-01,\n",
       "        3.02080244e-01, -4.00736213e-01, -3.93591821e-01,  1.48023888e-01,\n",
       "        2.73647398e-01,  4.39175591e-02, -4.14358117e-02, -1.86490655e-01,\n",
       "        2.70241946e-01,  2.41500169e-01, -2.19024986e-01,  6.97776675e-02,\n",
       "        7.71918818e-02,  1.55403152e-01, -1.58527195e-01,  2.41324455e-01,\n",
       "       -3.87599707e-01,  1.93816319e-01, -4.06315058e-01,  7.27281928e-01,\n",
       "       -4.45105806e-02, -1.85964718e-01, -1.68228164e-01,  1.14905097e-01,\n",
       "        5.89850783e-01,  4.00621146e-01,  2.43858263e-01, -7.78697580e-02,\n",
       "        8.14617891e-03,  8.96071084e-03, -1.47608519e-01, -2.76688576e-01,\n",
       "       -4.58644748e-01, -5.08388579e-01,  2.96203971e-01, -1.52879670e-01,\n",
       "       -3.94549817e-02, -2.01959953e-01,  1.70527726e-01,  6.02013588e-01,\n",
       "       -4.73922402e-01,  2.27606133e-01,  6.76049471e-01,  3.97662193e-01,\n",
       "        2.49736056e-01, -1.91063836e-01, -2.85557985e-01,  8.10671002e-02,\n",
       "       -2.44811684e-01, -2.57480219e-02,  6.49909824e-02,  4.84852307e-02,\n",
       "        4.77206945e-01,  2.37782031e-01,  4.49718833e-01, -3.35597277e-01,\n",
       "       -2.43506074e-01,  3.21920253e-02, -1.21632628e-01, -7.85495117e-02,\n",
       "        8.69653895e-02,  1.45968571e-01, -1.75944895e-01,  5.94180003e-02,\n",
       "       -4.58959155e-02,  1.36729613e-01,  3.48997474e-01,  1.18523195e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out how 'iphone' is represented (an array of 100 numbers)\n",
    "\n",
    "model.wv.get_vector('iphone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "465e6d2e4ff285001317589a5abcc0a7a64607aa"
   },
   "source": [
    "## Now, why are word embeddings powerful? \n",
    "\n",
    "This is because they capture the semantics relationships between words. In other words, words with similar meanings should appear near each other in the vector space of our custom embeddings.\n",
    "\n",
    "Lets check out an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "3dfbc936126bc2fa261b244fb2ffca4c88887ba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iphones', 0.7185158133506775),\n",
       " ('originaliphone', 0.6419346332550049),\n",
       " ('cpo', 0.6294914484024048),\n",
       " ('jetblack', 0.6190686821937561),\n",
       " ('mateblack', 0.6137925982475281),\n",
       " ('iphoneplus', 0.6127023100852966),\n",
       " ('exinternasional', 0.6091649532318115),\n",
       " ('apple', 0.6091042757034302),\n",
       " ('iph', 0.6079336404800415),\n",
       " ('selleriphone', 0.6071897745132446)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find words with similar meaning to 'iphone'\n",
    "\n",
    "model.wv.most_similar('iphone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "686e58aee82c64f9602fecc97fe554c031c2ce9a"
   },
   "source": [
    "Well, you will see words similar to 'iphone', sorted based on euclidean distance.\n",
    "Of cause, there are also not so intuitive and relevant ones (e.g. jetblack, cpo, ten). If you would like to tackle this, you can do a more thorough pre-processing/ try other embedding dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d18e90fe3baf47224ec8452c853916d514b9a3ad"
   },
   "source": [
    "## **The most important part!**\n",
    "Last but not least, save your word embeddings, so that you can used it for modelling. You can load the text file next time using Gensim KeyedVector function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "617b3112a72305368bd235290fe393bc16577fbf"
   },
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('custom_glove_300d.txt')\n",
    "\n",
    "\n",
    "# How to load:\n",
    "# w2v = KeyedVectors.load_word2vec_format('custom_glove_100d.txt')\n",
    "\n",
    "# How to get vector using loaded model\n",
    "# w2v.get_vector('iphone')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
